{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Detecting Depression using TF-IDF and BoW Methods","metadata":{}},{"cell_type":"code","source":"## Checking the Dataset\n\nimport pandas as pd\nimport numpy as np\n\ntweets = pd.read_csv(\"../input/depression-analysis/sentiment_tweets3.csv\")\ntweets.head(20)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-18T20:27:24.865074Z","iopub.execute_input":"2022-03-18T20:27:24.865452Z","iopub.status.idle":"2022-03-18T20:27:24.905271Z","shell.execute_reply.started":"2022-03-18T20:27:24.865406Z","shell.execute_reply":"2022-03-18T20:27:24.904444Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"The Dataset has 3 columns now. The first **Unnamed Column** is not useful to do any analysis. The second column is any **message** ever tweeted and third column is the **label** marker for each Tweet. If the Tweet was indicating signs of depression then it is 1 and if not then it is 0. \n\n*Removing the First column.....*","metadata":{}},{"cell_type":"code","source":"tweets.drop(['Unnamed: 0'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T20:27:27.704754Z","iopub.execute_input":"2022-03-18T20:27:27.705057Z","iopub.status.idle":"2022-03-18T20:27:27.711343Z","shell.execute_reply.started":"2022-03-18T20:27:27.705011Z","shell.execute_reply":"2022-03-18T20:27:27.710381Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"tweets.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T20:27:33.368267Z","iopub.execute_input":"2022-03-18T20:27:33.369078Z","iopub.status.idle":"2022-03-18T20:27:33.380976Z","shell.execute_reply.started":"2022-03-18T20:27:33.369039Z","shell.execute_reply":"2022-03-18T20:27:33.380022Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"## Splitting into Test and Train Data\n\n95% of the Dataset is used in Training. Rest will be used for Testing.","metadata":{}},{"cell_type":"code","source":"trainId, testId = list(), list()\nfor i in range(tweets.shape[0]):\n    if np.random.uniform(0, 1) < 0.95:\n        trainId += [i]\n    else:\n        testId += [i]\ntrainData = tweets.iloc[trainId]\ntestData = tweets.iloc[testId]","metadata":{"execution":{"iopub.status.busy":"2022-03-18T20:27:41.445202Z","iopub.execute_input":"2022-03-18T20:27:41.445458Z","iopub.status.idle":"2022-03-18T20:27:41.482011Z","shell.execute_reply.started":"2022-03-18T20:27:41.445430Z","shell.execute_reply":"2022-03-18T20:27:41.481284Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"print(\"Number of Depressive Tweets in Training set is {}\".format(trainData['label'].value_counts()[0]))\nprint(\"Number of Non-Depressive Tweets in Training set is {} \\n\".format(trainData['label'].value_counts()[1]))\nprint(\"Number of Depressive Tweets in Test set is {}\".format(testData['label'].value_counts()[0]))\nprint(\"Number of Non-Depressive Tweets in Test set is {}\".format(testData['label'].value_counts()[1]))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T20:27:43.889714Z","iopub.execute_input":"2022-03-18T20:27:43.889969Z","iopub.status.idle":"2022-03-18T20:27:43.899043Z","shell.execute_reply.started":"2022-03-18T20:27:43.889942Z","shell.execute_reply":"2022-03-18T20:27:43.898063Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"The above values give the number of Depressive and non depressive Tweets in the split dataset.","metadata":{}},{"cell_type":"markdown","source":"## Wordcloud Analysis","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt \n\ndef wordc(k):\n    words = ' '.join(list(tweets[tweets['label'] == k]['message']))\n    wc = WordCloud(width = 512,height = 512, collocations=False, colormap=\"Blues\").generate(words)\n    return(wc)\n\nfig , (ax1, ax2) = plt.subplots(1,2 , figsize = (10, 8) )\nax1.imshow(wordc(1))\nax1.set_title(\"Depressive Words\")\nax2.imshow(wordc(0))\nax2.set_title(\"Positive Words\")\nax1.axis('off')\nax2.axis('off')\nplt.tight_layout(pad = 1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T20:28:14.834812Z","iopub.execute_input":"2022-03-18T20:28:14.835517Z","iopub.status.idle":"2022-03-18T20:28:17.086222Z","shell.execute_reply.started":"2022-03-18T20:28:14.835478Z","shell.execute_reply":"2022-03-18T20:28:17.085322Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\n\nfrom math import log, sqrt\nimport re\n\ndef process_message(message, lower_case = True, stem = True, stop_words = True, gram = 2):\n    if lower_case:\n        message = message.lower()\n        \n    words = word_tokenize(message)\n    words = [w for w in words if len(w) > 2]\n    \n    if gram > 1:\n        w = []\n        for i in range(len(words) - gram + 1):\n            w += [' '.join(words[i:i + gram])]\n        return w\n    \n    if stop_words:\n        sw = stopwords.words('english')\n        words = [word for word in words if word not in sw]\n        \n    if stem:\n        stemmer = PorterStemmer()\n        words = [stemmer.stem(word) for word in words]  \n        \n    return words","metadata":{"execution":{"iopub.status.busy":"2022-03-18T20:28:34.481510Z","iopub.execute_input":"2022-03-18T20:28:34.481959Z","iopub.status.idle":"2022-03-18T20:28:34.491284Z","shell.execute_reply.started":"2022-03-18T20:28:34.481919Z","shell.execute_reply":"2022-03-18T20:28:34.490107Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"class TweetClassifier(object):\n    \n    def __init__(self, trainData, method = 'tf-idf'):\n        self.tweets, self.labels = trainData['message'], trainData['label']\n        self.method = method\n\n    def train(self):\n        self.calc_TF_and_IDF()\n        if self.method == 'tf-idf':\n            self.calc_TF_IDF()\n        else:\n            self.calc_prob()\n\n    def calc_prob(self):\n        self.prob_depressive = dict()\n        self.prob_positive = dict()\n        for word in self.tf_depressive:\n            self.prob_depressive[word] = (self.tf_depressive[word] + 1) / (self.depressive_words + \\\n                                                                len(list(self.tf_depressive.keys())))\n        for word in self.tf_positive:\n            self.prob_positive[word] = (self.tf_positive[word] + 1) / (self.positive_words + \\\n                                                                len(list(self.tf_positive.keys())))\n        self.prob_depressive_tweet, self.prob_positive_tweet = self.depressive_tweets / self.total_tweets, self.positive_tweets / self.total_tweets \n\n\n    def calc_TF_and_IDF(self):\n        noOfMessages = self.tweets.shape[0]\n        self.depressive_tweets, self.positive_tweets = self.labels.value_counts()[1], self.labels.value_counts()[0]\n        self.total_tweets = self.depressive_tweets + self.positive_tweets\n        self.depressive_words = 0\n        self.positive_words = 0\n        self.tf_depressive = dict()\n        self.tf_positive = dict()\n        self.idf_depressive = dict()\n        self.idf_positive = dict()\n        for i in range(noOfMessages):\n            message_processed = process_message(self.tweets.iloc[i])\n            count = list() #To keep track of whether the word has ocured in the message or not.\n                           #For IDF\n            for word in message_processed:\n                if self.labels.iloc[i]:\n                    self.tf_depressive[word] = self.tf_depressive.get(word, 0) + 1\n                    self.depressive_words += 1\n                else:\n                    self.tf_positive[word] = self.tf_positive.get(word, 0) + 1\n                    self.positive_words += 1\n                if word not in count:\n                    count += [word]\n            for word in count:\n                if self.labels.iloc[i]:\n                    self.idf_depressive[word] = self.idf_depressive.get(word, 0) + 1\n                else:\n                    self.idf_positive[word] = self.idf_positive.get(word, 0) + 1\n    def calc_TF_IDF(self):\n        self.prob_depressive = dict()\n        self.prob_positive = dict()\n        self.sum_tf_idf_depressive = 0\n        self.sum_tf_idf_positive = 0\n        for word in self.tf_depressive:\n            self.prob_depressive[word] = (self.tf_depressive[word]) * log((self.depressive_tweets + self.positive_tweets) \\\n                                                          / (self.idf_depressive[word] + self.idf_positive.get(word, 0)))\n            self.sum_tf_idf_depressive += self.prob_depressive[word]\n        for word in self.tf_depressive:\n            self.prob_depressive[word] = (self.prob_depressive[word] + 1) / (self.sum_tf_idf_depressive + len(list(self.prob_depressive.keys())))\n            \n        for word in self.tf_positive:\n            self.prob_positive[word] = (self.tf_positive[word]) * log((self.depressive_tweets + self.positive_tweets) \\\n                                                          / (self.idf_depressive.get(word, 0) + self.idf_positive[word]))\n            self.sum_tf_idf_positive += self.prob_positive[word]\n        for word in self.tf_positive:\n            self.prob_positive[word] = (self.prob_positive[word] + 1) / (self.sum_tf_idf_positive + len(list(self.prob_positive.keys())))\n            \n    \n        self.prob_depressive_tweet, self.prob_positive_tweet = self.depressive_tweets / self.total_tweets, self.positive_tweets / self.total_tweets \n                    \n    def classify(self, processed_message):\n        pDepressive, pPositive = 0, 0\n        for word in processed_message:                \n            if word in self.prob_depressive:\n                pDepressive += log(self.prob_depressive[word])\n            else:\n                if self.method == 'tf-idf':\n                    pDepressive -= log(self.sum_tf_idf_depressive + len(list(self.prob_depressive.keys())))\n                else:\n                    pDepressive -= log(self.depressive_words + len(list(self.prob_depressive.keys())))\n            if word in self.prob_positive:\n                pPositive += log(self.prob_positive[word])\n            else:\n                if self.method == 'tf-idf':\n                    pPositive -= log(self.sum_tf_idf_positive + len(list(self.prob_positive.keys()))) \n                else:\n                    pPositive -= log(self.positive_words + len(list(self.prob_positive.keys())))\n            pDepressive += log(self.prob_depressive_tweet)\n            pPositive += log(self.prob_positive_tweet)\n        return(pDepressive >= pPositive)\n\n    def predict(self, testData):\n        result = dict()\n        for (i, message) in enumerate(testData):\n            processed_message = process_message(message)\n            result[i] = int(self.classify(processed_message))\n        return result","metadata":{"execution":{"iopub.status.busy":"2022-03-18T20:32:06.342665Z","iopub.execute_input":"2022-03-18T20:32:06.342989Z","iopub.status.idle":"2022-03-18T20:32:06.368310Z","shell.execute_reply.started":"2022-03-18T20:32:06.342959Z","shell.execute_reply":"2022-03-18T20:32:06.367103Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"def metrics(labels, predictions):\n    true_pos, true_neg, false_pos, false_neg = 0, 0, 0, 0\n    \n    for i in range(len(labels)):\n        true_pos += int(labels.iloc[i] == 1 and predictions[i] == 1)\n        true_neg += int(labels.iloc[i] == 0 and predictions[i] == 0)\n        false_pos += int(labels.iloc[i] == 0 and predictions[i] == 1)\n        false_neg += int(labels.iloc[i] == 1 and predictions[i] == 0)\n        \n\n    precision = true_pos / (true_pos + false_pos)\n    recall = true_pos / (true_pos + false_neg)\n    Fscore = 2 * precision * recall / (precision + recall)\n    accuracy = (true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg)\n\n    print(\"Precision: \", precision)\n    print(\"Recall: \", recall)\n    print(\"F-score: \", Fscore)\n    print(\"Accuracy: \", accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T20:28:45.112165Z","iopub.execute_input":"2022-03-18T20:28:45.112711Z","iopub.status.idle":"2022-03-18T20:28:45.119465Z","shell.execute_reply.started":"2022-03-18T20:28:45.112676Z","shell.execute_reply":"2022-03-18T20:28:45.118441Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"sc_tf_idf = TweetClassifier(trainData, 'tf-idf')\nsc_tf_idf.train()\npreds_tf_idf = sc_tf_idf.predict(testData['message'])\nmetrics(testData['label'], preds_tf_idf)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T20:32:12.405439Z","iopub.execute_input":"2022-03-18T20:32:12.405772Z","iopub.status.idle":"2022-03-18T20:32:53.859610Z","shell.execute_reply.started":"2022-03-18T20:32:12.405735Z","shell.execute_reply":"2022-03-18T20:32:53.858631Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"sc_bow = TweetClassifier(trainData, 'bow')\nsc_bow.train()\npreds_bow = sc_bow.predict(testData['message'])\nmetrics(testData['label'], preds_bow)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T20:32:59.265040Z","iopub.execute_input":"2022-03-18T20:32:59.265785Z","iopub.status.idle":"2022-03-18T20:33:41.993200Z","shell.execute_reply.started":"2022-03-18T20:32:59.265748Z","shell.execute_reply":"2022-03-18T20:33:41.992304Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"tweet = process_message('Extreme sadness')\nprint(sc_tf_idf.classify(tweet))\nprint(sc_bow.classify(tweet))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T20:35:07.449446Z","iopub.execute_input":"2022-03-18T20:35:07.450015Z","iopub.status.idle":"2022-03-18T20:35:07.458201Z","shell.execute_reply.started":"2022-03-18T20:35:07.449978Z","shell.execute_reply":"2022-03-18T20:35:07.457358Z"},"trusted":true},"execution_count":85,"outputs":[]}]}